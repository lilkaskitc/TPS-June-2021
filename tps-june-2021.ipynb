{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Since TPS June 2021 is a further extension on the [TPS May 2021](http://www.kaggle.com/c/tabular-playground-series-may-2021) multiclass classification problem with more samples and anonymous features together with target classes increasing from 4 to 9, we have already try to break down the modelling process fundamentally last month, so this time we will try to tackle the problem by Optuna to automate the hyperparameter tuning. Moreover, this solution will try to utilise the free GPU accelerator provided by Kaggle for practising purpose.\n\nBased on the background above, you will see a solution in favour of simple ML workflow and low computation cost, ready to be deployed for different problems. The presentation may be raw, but I will keep it to show how the result is improved gradually.\n\nWorkflow:\n1. Data Exploration\n2. Data Preprocessing\n3. Feature Engineering\n4. Feature Selection\n5. Base Models\n6. Stacking","metadata":{}},{"cell_type":"markdown","source":"# Preparation","metadata":{"execution":{"iopub.status.busy":"2021-05-23T06:58:55.274806Z","iopub.execute_input":"2021-05-23T06:58:55.275347Z","iopub.status.idle":"2021-05-23T06:58:55.281032Z","shell.execute_reply.started":"2021-05-23T06:58:55.275243Z","shell.execute_reply":"2021-05-23T06:58:55.279899Z"}}},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"# Essentials\nimport numpy as np\nimport pandas as pd\nimport datetime\nimport random\n\n# Plots\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Models\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor, ExtraTreesClassifier, StackingClassifier\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.linear_model import RidgeClassifier, RidgeCV\nfrom sklearn.linear_model import ElasticNet, ElasticNetCV, LogisticRegressionCV, LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom mlxtend.classifier import StackingCVClassifier\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import Pool, CatBoostClassifier\n\n# Stats\nfrom scipy.stats import skew, norm\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\n\n# Misc\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score, validation_curve\nfrom sklearn.metrics import log_loss, confusion_matrix\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import scale\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.calibration import CalibratedClassifierCV\n\npd.set_option('display.max_columns', None)\n\n# Ignore useless warnings\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")\npd.options.display.max_seq_items = 8000\npd.options.display.max_rows = 8000\n\nimport os\nos.listdir(\"../input/\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-30T23:48:32.881375Z","iopub.execute_input":"2021-06-30T23:48:32.881847Z","iopub.status.idle":"2021-06-30T23:48:36.417455Z","shell.execute_reply.started":"2021-06-30T23:48:32.881778Z","shell.execute_reply":"2021-06-30T23:48:36.41624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read data","metadata":{}},{"cell_type":"code","source":"# Read in the dataset as a dataframe\ntrain = pd.read_csv(\"../input/tabular-playground-series-jun-2021/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-jun-2021/test.csv\")\nsubmission = pd.read_csv(\"../input/tabular-playground-series-jun-2021/sample_submission.csv\")\n\n#train.info()\n#test.info()\n#submission.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:36.420188Z","iopub.execute_input":"2021-06-30T23:48:36.420436Z","iopub.status.idle":"2021-06-30T23:48:38.412618Z","shell.execute_reply.started":"2021-06-30T23:48:36.420412Z","shell.execute_reply":"2021-06-30T23:48:38.411642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split datasets","metadata":{}},{"cell_type":"code","source":"# Split features and labels\ntrain_labels = train['target'].reset_index(drop=True)\ntrain_features = train.drop(['id','target'], axis=1)\ntest_features = test.drop(['id'], axis=1)\ntrain_labels.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:38.414369Z","iopub.execute_input":"2021-06-30T23:48:38.41477Z","iopub.status.idle":"2021-06-30T23:48:38.478787Z","shell.execute_reply.started":"2021-06-30T23:48:38.414741Z","shell.execute_reply":"2021-06-30T23:48:38.477639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train\ndel test","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:38.480235Z","iopub.execute_input":"2021-06-30T23:48:38.480516Z","iopub.status.idle":"2021-06-30T23:48:38.487109Z","shell.execute_reply.started":"2021-06-30T23:48:38.480487Z","shell.execute_reply":"2021-06-30T23:48:38.485917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration","metadata":{}},{"cell_type":"markdown","source":"## Target distribution\n\nAs observed, 26% each of the target in the training set is of respectively \"Class 6\" & \"Class 8\", which is pretty balanced among 9 classes.","metadata":{}},{"cell_type":"code","source":"'''\nsns.set_style(\"white\")\nsns.set_color_codes(palette='deep')\nf, ax = plt.subplots(figsize=(8, 7))\n#Check the new distribution \nsns.histplot(train['target'].sort_values(), color=\"b\");\nax.xaxis.grid(False)\nax.set(ylabel=\"Frequency\")\nax.set(xlabel=\"Target\")\nax.set(title=\"Target distribution\")\nsns.despine(trim=True, left=True)\nplt.show()\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:38.488942Z","iopub.execute_input":"2021-06-30T23:48:38.489316Z","iopub.status.idle":"2021-06-30T23:48:38.506052Z","shell.execute_reply.started":"2021-06-30T23:48:38.489286Z","shell.execute_reply":"2021-06-30T23:48:38.504674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train['target'].value_counts().sort_values(ascending=False)/sum(train['target'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:38.50759Z","iopub.execute_input":"2021-06-30T23:48:38.507999Z","iopub.status.idle":"2021-06-30T23:48:38.522943Z","shell.execute_reply.started":"2021-06-30T23:48:38.507968Z","shell.execute_reply":"2021-06-30T23:48:38.521762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Features EDA\n\nNo specific pattern is observed in this case.","metadata":{}},{"cell_type":"code","source":"'''\n# visualising some more outliers in the data values\nfig, axs = plt.subplots(ncols=2, nrows=1, figsize=(12, 120))\nplt.subplots_adjust(right=2)\nplt.subplots_adjust(top=2)\nsns.color_palette(\"husl\", 8)\nfor i, feature in enumerate(list(train_features), 1):\n    plt.subplot(len(list(train_features)), 3, i)\n    sns.boxplot(x=feature, y=train_labels, hue=train_labels, palette='Blues', data=train_features)\n        \n    plt.xlabel('{}'.format(feature), size=15,labelpad=12.5)\n    plt.ylabel('Target', size=15, labelpad=12.5)\n    \n    for j in range(2):\n        plt.tick_params(axis='x', labelsize=12)\n        plt.tick_params(axis='y', labelsize=12)\n    \n    plt.legend(loc='best', prop={'size': 10})\n        \nplt.show()\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:38.524317Z","iopub.execute_input":"2021-06-30T23:48:38.524582Z","iopub.status.idle":"2021-06-30T23:48:38.54473Z","shell.execute_reply.started":"2021-06-30T23:48:38.524555Z","shell.execute_reply":"2021-06-30T23:48:38.543511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correlation\n\nFilter by RF feature importance first when the number of features is too large.\n\nThe 50 features show no significant correlation with each other.","metadata":{}},{"cell_type":"code","source":"'''\n# Random Forest Classifier\nrf = RandomForestClassifier(n_estimators=100, random_state=42)\n\nrf_model = rf.fit(train_features, train_labels)\n#rf_pred = rf_model.predict_proba(test_features)\n\nforest_importances = pd.Series(rf.feature_importances_, index=train_features.columns)\ntop_feat = forest_importances.sort_values(ascending = False).head(20)\ntop_feat\n\ntrain_features[top_feat.index]\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:38.547986Z","iopub.execute_input":"2021-06-30T23:48:38.548388Z","iopub.status.idle":"2021-06-30T23:48:38.557845Z","shell.execute_reply.started":"2021-06-30T23:48:38.548353Z","shell.execute_reply":"2021-06-30T23:48:38.55666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ncorr = train_features[top_feat.index].corr()\n#corr\n#corr = train.corr()\nplt.subplots(figsize=(15,12))\nsns.heatmap(corr, vmax=0.9, cmap=\"Blues\", square=True)\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:38.559704Z","iopub.execute_input":"2021-06-30T23:48:38.559982Z","iopub.status.idle":"2021-06-30T23:48:38.580921Z","shell.execute_reply.started":"2021-06-30T23:48:38.559955Z","shell.execute_reply":"2021-06-30T23:48:38.57983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Further exploration for high correlation to target\n\nThe most important features by RF is feature_54, but visually its standalone correlation with the target is insignificant.","metadata":{}},{"cell_type":"code","source":"'''\ndata = pd.concat([train['feature_54'], train['target']], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=train['feature_54'], y=\"target\", data=data)\n#fig.axis(ymin=0, ymax=800000);\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:38.583672Z","iopub.execute_input":"2021-06-30T23:48:38.583948Z","iopub.status.idle":"2021-06-30T23:48:38.600749Z","shell.execute_reply.started":"2021-06-30T23:48:38.58392Z","shell.execute_reply":"2021-06-30T23:48:38.599475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"Label encoding for features","metadata":{}},{"cell_type":"code","source":"\nencoder = OrdinalEncoder()\nall_encoded = encoder.fit_transform(train_features.append(test_features))\ntrain_features_encoded = all_encoded[0:len(train_features)]\ntest_features_encoded = all_encoded[len(train_features):]\n","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:38.602021Z","iopub.execute_input":"2021-06-30T23:48:38.602335Z","iopub.status.idle":"2021-06-30T23:48:40.092627Z","shell.execute_reply.started":"2021-06-30T23:48:38.602305Z","shell.execute_reply":"2021-06-30T23:48:40.091467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_features\ndel test_features\ndel all_encoded","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:40.094853Z","iopub.execute_input":"2021-06-30T23:48:40.095228Z","iopub.status.idle":"2021-06-30T23:48:40.099989Z","shell.execute_reply.started":"2021-06-30T23:48:40.095197Z","shell.execute_reply":"2021-06-30T23:48:40.099297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No outliers or missing values observed from EDA.","metadata":{}},{"cell_type":"markdown","source":"## Recombine datasets\n\nNo treatment is needed in this case.","metadata":{}},{"cell_type":"markdown","source":"# Feature Engineering\n\nSince the features are anonymous and having considerable size, the features space can be pretty large if we adopt some brute force interactive opreations. This will significantly increase the computational cost, hence feature engineering of this sort is not considered in this problem.","metadata":{}},{"cell_type":"markdown","source":"## PCA\n\nSince there are 75 features, the dimension reduction technique may help. I have tried PCA, but the result is not satisfactory. This is intuitive given the low features correlation shown in EDA, and the almost identical contributions from all the principal components.","metadata":{}},{"cell_type":"code","source":"'''\nX=train_features\n# Standardize\nX_scaled = (X - X.mean(axis=0)) / X.std(axis=0)\n\n# Create principal components\npca = PCA()\nX_pca = pca.fit_transform(X_scaled)\n\n# Convert to dataframe\ncomponent_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\nX_pca = pd.DataFrame(X_pca, columns=component_names)\n\nX_pca.head()\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:40.136377Z","iopub.execute_input":"2021-06-30T23:48:40.136733Z","iopub.status.idle":"2021-06-30T23:48:40.153332Z","shell.execute_reply.started":"2021-06-30T23:48:40.136704Z","shell.execute_reply":"2021-06-30T23:48:40.152063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nloadings = pd.DataFrame(\n    pca.components_.T,  # transpose the matrix of loadings\n    columns=component_names,  # so the columns are the principal components\n    index=X.columns,  # and the rows are the original features\n)\nloadings\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:40.154606Z","iopub.execute_input":"2021-06-30T23:48:40.154888Z","iopub.status.idle":"2021-06-30T23:48:40.17424Z","shell.execute_reply.started":"2021-06-30T23:48:40.15485Z","shell.execute_reply":"2021-06-30T23:48:40.173327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ndef plot_variance(pca, width=8, dpi=100):\n    # Create figure\n    fig, axs = plt.subplots(1, 2)\n    n = pca.n_components_\n    grid = np.arange(1, n + 1)\n    # Explained variance\n    evr = pca.explained_variance_ratio_\n    axs[0].bar(grid, evr)\n    axs[0].set(\n        xlabel=\"Component\", title=\"% Explained Variance\", ylim=(0.0, 0.1)\n    )\n    # Cumulative Variance\n    cv = np.cumsum(evr)\n    axs[1].plot(np.r_[0, grid], np.r_[0, cv], \"o-\")\n    axs[1].set(\n        xlabel=\"Component\", title=\"% Cumulative Variance\", ylim=(0.0, 1.0)\n    )\n    # Set up figure\n    fig.set(figwidth=8, dpi=100)\n    return axs\n\n# Look at explained variance\nplot_variance(pca);\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:40.175396Z","iopub.execute_input":"2021-06-30T23:48:40.175927Z","iopub.status.idle":"2021-06-30T23:48:40.197471Z","shell.execute_reply.started":"2021-06-30T23:48:40.175889Z","shell.execute_reply":"2021-06-30T23:48:40.196407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ndef make_mi_scores(X, y, discrete_features):\n    mi_scores = mutual_info_classif(X, y, discrete_features=discrete_features)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\nmi_scores = make_mi_scores(X_pca, train_labels, discrete_features=False)\nmi_scores\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:40.198781Z","iopub.execute_input":"2021-06-30T23:48:40.199163Z","iopub.status.idle":"2021-06-30T23:48:40.216614Z","shell.execute_reply.started":"2021-06-30T23:48:40.199126Z","shell.execute_reply":"2021-06-30T23:48:40.215451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nmiindex = mi_scores.index[mi_scores.values>0]\nmiload = loadings[miindex]\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:40.217715Z","iopub.execute_input":"2021-06-30T23:48:40.217926Z","iopub.status.idle":"2021-06-30T23:48:40.235868Z","shell.execute_reply.started":"2021-06-30T23:48:40.217903Z","shell.execute_reply":"2021-06-30T23:48:40.235063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ntrain_features_pca = pd.DataFrame(data = np.matmul(train_features,miload))\ntrain_features_pca.columns=miindex\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:40.237169Z","iopub.execute_input":"2021-06-30T23:48:40.237623Z","iopub.status.idle":"2021-06-30T23:48:40.251348Z","shell.execute_reply.started":"2021-06-30T23:48:40.237587Z","shell.execute_reply":"2021-06-30T23:48:40.250233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ntest_features_pca = pd.DataFrame(data = np.matmul(test_features,miload))\ntest_features_pca.columns=miindex\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:40.253139Z","iopub.execute_input":"2021-06-30T23:48:40.253418Z","iopub.status.idle":"2021-06-30T23:48:40.268447Z","shell.execute_reply.started":"2021-06-30T23:48:40.25339Z","shell.execute_reply":"2021-06-30T23:48:40.267347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Recreate training and test sets\n\nNo treatment is needed in this case.","metadata":{}},{"cell_type":"markdown","source":"# Feature Selection","metadata":{}},{"cell_type":"markdown","source":"# Base Models","metadata":{}},{"cell_type":"markdown","source":"## Optuna try","metadata":{}},{"cell_type":"code","source":"\n# Optuna for parameter search\n!pip install -q optuna\n\nimport optuna\nimport pickle\n","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:40.269656Z","iopub.execute_input":"2021-06-30T23:48:40.270014Z","iopub.status.idle":"2021-06-30T23:48:50.388589Z","shell.execute_reply.started":"2021-06-30T23:48:40.269977Z","shell.execute_reply":"2021-06-30T23:48:50.387551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Transform the target to numbers exactly as the class numbers","metadata":{}},{"cell_type":"code","source":"\ndef class_to_num(classes):\n    return [int(word[-1]) for word in classes]\n\n#def num_to_class(nums):\n #   return ['Class_' + str(num) for num in nums]\n\n#class type array starts from zero\ntrain_labels_num = np.array(class_to_num(train_labels))-1\ntrain_labels_num\n","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.394489Z","iopub.execute_input":"2021-06-30T23:48:50.394949Z","iopub.status.idle":"2021-06-30T23:48:50.531075Z","shell.execute_reply.started":"2021-06-30T23:48:50.394919Z","shell.execute_reply":"2021-06-30T23:48:50.529909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_labels","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.534268Z","iopub.execute_input":"2021-06-30T23:48:50.534673Z","iopub.status.idle":"2021-06-30T23:48:50.53859Z","shell.execute_reply.started":"2021-06-30T23:48:50.534638Z","shell.execute_reply":"2021-06-30T23:48:50.537762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Light GBM","metadata":{}},{"cell_type":"code","source":"'''\n\n\nparams = {\n    \n    \n    'reg_lambda': 405.6123975349561, \n     'reg_alpha': 0.09452256681364866, \n     'colsample_bytree': 0.31486263497374173, \n     'subsample': 0.7281301644169369,\n     'learning_rate': 0.01, \n     'num_leaves': 135,\n     'min_child_samples': 489,\n     'max_depth': 29\n}\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.539791Z","iopub.execute_input":"2021-06-30T23:48:50.540063Z","iopub.status.idle":"2021-06-30T23:48:50.559637Z","shell.execute_reply.started":"2021-06-30T23:48:50.540034Z","shell.execute_reply":"2021-06-30T23:48:50.558293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nX=train_features_encoded\ny=train_labels_num\n\nparams_lgbm = params\nparams_lgbm['boosting_type'] = 'gbdt'\nparams_lgbm['device'] = 'gpu'\nparams_lgbm ['objective'] = 'multiclasss'\nparams_lgbm ['num_classes'] = 9,\n\nparams_lgbm ['metric'] = 'multi_logloss'\nparams_lgbm ['verbosity'] = -1\nparams_lgbm ['n_estimators']= 100000\n#params_lgbm[\"cat_feature\"] = cat_features\n\nname = 'lightgbm_3seed_5fold'\nk=5\nseed_list=[0,1,2]\nrandom_seed=0\nkf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\noof = np.zeros((len(X),9))\ntest_preds_list = []\nscore_list = []\nfold=1\n  \nsplits = list(kf.split(X,y))\nfold = 1\nfor train_idx, val_idx in splits:\n  X_train, X_val = X[train_idx], X[val_idx]\n  y_train, y_val = y[train_idx], y[val_idx]\n\n  val_preds_list = []\n\n  for seed in seed_list:\n    \n    # fit and run model\n    params_lgbm['random_state'] = seed\n    \n    model = LGBMClassifier(**params_lgbm)\n    \n    model.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_val,y_val)],\n              early_stopping_rounds=100,\n              eval_names=['train','val'],verbose=200)\n\n    \n    val_preds_list.append(model.predict_proba(X_val))\n    test_preds_list.append(model.predict_proba(test_features_encoded))\n    \n  oof[val_idx] = np.mean(val_preds_list,axis=0)\n  score = log_loss(y_val, oof[val_idx])\n  print(f\"fold: {fold},log_loss: {score}\")\n  score_list.append(score)\n  # print(f\"fold: {fold}, class0 tr %: {y_train.value_counts()[0]/len(y_train)}, class0 val %: {y_val.value_counts()[0]/len(y_val)} \")\n  fold +=1\n  \ncv_logloss = np.mean(score_list)\nprint(f\"{name} ,log_loss: {cv_logloss}\")\n\npreds= np.mean(test_preds_list,axis=0)\n\n\nfile_name_oof = name +\"_oof.txt\"\nfile_name_test = name + \"_test.csv\"\nwith open(file_name_oof, \"wb\") as fp:\n      pickle.dump(oof, fp)\n\n#files.download(file_name_oof)\nsubmission.iloc[:,1:] = pd.DataFrame(preds)\nsubmission.to_csv(file_name_test,index=None)\n#files.download(file_name_test) \n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.561445Z","iopub.execute_input":"2021-06-30T23:48:50.56177Z","iopub.status.idle":"2021-06-30T23:48:50.582508Z","shell.execute_reply.started":"2021-06-30T23:48:50.561741Z","shell.execute_reply":"2021-06-30T23:48:50.581635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Light GBM tuning","metadata":{}},{"cell_type":"code","source":"'''\n# for the fixed learning rate, use the opt n iterations and tune the tree hyperparameters\ndef objective(trial, X=train_features_encoded, y=train_labels_num):\n  \"\"\"\n  \"\"\"\n  param_space = {\n               'device':'gpu',  # Use GPU acceleration\n               'boosting_type': 'gbdt',\n               'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 1e3),\n               'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 1e3),\n               'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1 , 1.0),\n               'subsample': trial.suggest_float('subsample', 0.1, 1.0),\n                #'subsample_freq': trial.suggest_int('subsample_freq', 1, 10),\n               'learning_rate': trial.suggest_loguniform('learning_rate', 1e-2, 1e-2),\n               'num_leaves': trial.suggest_int(\"num_leaves\", 31,256),\n               'min_child_samples': trial.suggest_int('min_child_samples', 1, 500),\n               'max_depth':trial.suggest_int('max_depth',3,127),\n              #'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 0.005),\n              #'class_weight':trial.suggest_categorical('class_weight',['balanced',None]),\n               'n_estimators':100000,\n               'objective':'multiclass',\n               'metric':'multi_logloss'\n                }\n            \n  #X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=.1,random_state=2021,stratify=y)\n  k=5\n  seed_list=[0]\n  random_seed=0\n  kf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\n  oof = np.zeros((len(X),9))\n  score_list = []\n  fold=1\n  \n  splits = list(kf.split(X,y))\n  for train_idx, val_idx in splits:\n    X_train, X_val = X[train_idx,:], X[val_idx,:]\n    y_train, y_val = y[train_idx], y[val_idx]\n  \n    val_preds_list = []\n  \n    for seed in seed_list:\n      # fit and run model\n      param_space['random_state'] = seed\n\n      model = LGBMClassifier(**param_space)\n      model.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_val,y_val)],\n                early_stopping_rounds=100,\n                eval_names=['train','val'],verbose=0)\n    \n      val_preds_list.append(model.predict_proba(X_val))\n     #test_preds_list.append(model.predict_proba(X_test)[:,1])\n    \n    oof[val_idx] = np.mean(val_preds_list,axis=0)\n    score = log_loss(y_val, oof[val_idx])\n    print(f\"fold: {fold},logloss: {score}\")\n    score_list.append(score)\n    fold +=1\n  \n  cv_logloss = np.mean(score_list)\n  \n  return cv_logloss\n '''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.584961Z","iopub.execute_input":"2021-06-30T23:48:50.585233Z","iopub.status.idle":"2021-06-30T23:48:50.605836Z","shell.execute_reply.started":"2021-06-30T23:48:50.585208Z","shell.execute_reply":"2021-06-30T23:48:50.604668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n%%time\n\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective,n_trials= 20)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.607548Z","iopub.execute_input":"2021-06-30T23:48:50.607935Z","iopub.status.idle":"2021-06-30T23:48:50.6296Z","shell.execute_reply.started":"2021-06-30T23:48:50.607905Z","shell.execute_reply":"2021-06-30T23:48:50.628685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#study.best_params","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.632209Z","iopub.execute_input":"2021-06-30T23:48:50.632511Z","iopub.status.idle":"2021-06-30T23:48:50.644168Z","shell.execute_reply.started":"2021-06-30T23:48:50.632485Z","shell.execute_reply":"2021-06-30T23:48:50.643619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### XGBoost","metadata":{}},{"cell_type":"code","source":"import xgboost","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.645001Z","iopub.execute_input":"2021-06-30T23:48:50.645303Z","iopub.status.idle":"2021-06-30T23:48:50.663767Z","shell.execute_reply.started":"2021-06-30T23:48:50.64527Z","shell.execute_reply":"2021-06-30T23:48:50.663133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nparams =  {\n 'lambda': 1.916220456301414, \n 'alpha': 7.860684965705271, \n 'colsample_bytree': 0.39793959188267636, \n 'colsample_bynode': 0.35770691759121553,\n 'colsample_bylevel': 0.43340183901358953, \n 'subsample': 0.639573806625875, \n 'eta': 0.01,\n 'grow_policy': 'depthwise', \n 'max_depth': 10, \n 'min_child_weight': 112,\n 'max_bin': 339, \n 'deterministic_histogram': False}\n'''\n","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.664635Z","iopub.execute_input":"2021-06-30T23:48:50.664904Z","iopub.status.idle":"2021-06-30T23:48:50.682963Z","shell.execute_reply.started":"2021-06-30T23:48:50.664876Z","shell.execute_reply":"2021-06-30T23:48:50.682237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nX=train_features_encoded\ny=train_labels_num\n\nparams_xgb = params\nparams_xgb[\"tree_method\"] = \"gpu_hist\"\nparams_xgb[\"predictor\"] = 'gpu_predictor'\nparams_xgb[\"objective\"] = 'multi:softprob'\nparams_xgb[\"num_class\"] = 9\nparams_xgb[\"eval_metric\"] ='mlogloss'\n\nname = 'xgboost_3seed_5fold'\nk=5\nseed_list=[0,1,2]\nrandom_seed=0\nkf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\noof = np.zeros((len(X),9))\ntest_preds_list = []\nscore_list = []\nfold=1\n  \nsplits = list(kf.split(X,y))\nfold = 1\nfor train_idx, val_idx in splits:\n  X_train, X_val = X[train_idx], X[val_idx]\n  y_train, y_val = y[train_idx], y[val_idx]\n\n  val_preds_list = []\n\n  for seed in seed_list:\n    \n    # fit and run model\n    params_xgb['seed'] = seed\n    \n    dtrain = xgboost.DMatrix(data=X_train, label=y_train)\n    dval = xgboost.DMatrix(data=X_val, label=y_val)\n    dtest = xgboost.DMatrix(data=test_features_encoded)\n    \n    model = xgboost.train(params_xgb, dtrain,\\\n                       evals=[(dtrain,'train'),(dval,'val')],\\\n                       verbose_eval=False,\n                       early_stopping_rounds=100,\n                       num_boost_round=100000)\n    \n    \n\n    \n    val_preds_list.append(model.predict(dval))\n    test_preds_list.append(model.predict(dtest))\n    \n  oof[val_idx] = np.mean(val_preds_list,axis=0)\n  score = log_loss(y_val, oof[val_idx])\n  print(f\"fold: {fold},log_loss: {score}\")\n  score_list.append(score)\n  # print(f\"fold: {fold}, class0 tr %: {y_train.value_counts()[0]/len(y_train)}, class0 val %: {y_val.value_counts()[0]/len(y_val)} \")\n  fold +=1\n  \ncv_logloss = np.mean(score_list)\nprint(f\"{name} ,log_loss: {cv_logloss}\")\n\npreds= np.mean(test_preds_list,axis=0)\n\n\nfile_name_oof = name + \"_oof.txt\"\nfile_name_test = name + \"_test.csv\"\nwith open(file_name_oof, \"wb\") as fp:\n      pickle.dump(oof, fp)\n\n#files.download(file_name_oof)\n\nsubmission.iloc[:,1:] = pd.DataFrame(preds)\nsubmission.to_csv(file_name_test,index=None)\n#files.download(file_name_test) \n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.683829Z","iopub.execute_input":"2021-06-30T23:48:50.684127Z","iopub.status.idle":"2021-06-30T23:48:50.698913Z","shell.execute_reply.started":"2021-06-30T23:48:50.684104Z","shell.execute_reply":"2021-06-30T23:48:50.698174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### XGBoost tuning","metadata":{}},{"cell_type":"code","source":"'''\n# for the fixed learning rate, use the opt n iterations and tune the tree hyperparameters\ndef objective(trial,X=train_features_encoded, y=train_labels_num):\n  \"\"\"\n  \"\"\"\n  param_space = { \n               'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n                'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 0.9),\n                'colsample_bynode': trial.suggest_float('colsample_bynode', 0.1, 0.9),\n                'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.1, 0.9),\n                'subsample': trial.suggest_float('subsample', 0.1, 0.9),\n                'eta':trial.suggest_float('eta', 1e-2, 1e-2),\n                'grow_policy': trial.suggest_categorical(\"grow_policy\", ['depthwise','lossguide']),\n                'max_depth': trial.suggest_int('max_depth',2,25),\n                'seed': 0,\n                'min_child_weight': trial.suggest_int('min_child_weight', 0, 300),\n                'max_bin': trial.suggest_int('max_bin', 256, 512),\n                'deterministic_histogram':trial.suggest_categorical('deterministic_histogram',[False]),\n               \"tree_method\" : \"gpu_hist\",\n                \"predictor\" : 'gpu_predictor',\n                \"objective\" : 'multi:softprob',\n                 \"num_class\":9\n                }\n            \n  #X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=.1,random_state=2021,stratify=y)\n  k=5\n  seed_list=[0]\n  random_seed=0\n  kf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\n  oof = np.zeros((len(X),9))\n  score_list = []\n  fold=1\n  \n  splits = list(kf.split(X,y))\n  for train_idx, val_idx in splits:\n    X_train, X_val = X[train_idx,:], X[val_idx,:]\n    y_train, y_val = y[train_idx], y[val_idx]\n  \n    val_preds_list = []\n  \n    for seed in seed_list:\n      # fit and run model\n      param_space['seed'] = seed\n      dtrain = xgboost.DMatrix(data=X_train, label=y_train)\n      dval = xgboost.DMatrix(data=X_val, label=y_val)\n      #dtest = xgboost.DMatrix(data=test_features_encoded)\n      xgboost.set_config(verbosity=0)\n\n      \n      model = xgboost.train(param_space, dtrain,\\\n                       evals=[(dtrain,'train'),(dval,'val')],\\\n                       verbose_eval=False,\n                       early_stopping_rounds=100,\n                       num_boost_round=100000)\n    \n    \n\n    \n      val_preds_list.append(model.predict(dval))\n     #test_preds_list.append(model.predict_proba(X_test)[:,1])\n    \n    oof[val_idx] = np.mean(val_preds_list,axis=0)\n    score = log_loss(y_val, oof[val_idx])\n    #print(f\"fold: {fold},logloss: {score}\")\n    score_list.append(score)\n    fold +=1\n  \n  cv_logloss = np.mean(score_list)\n  \n  return cv_logloss\n  '''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.699793Z","iopub.execute_input":"2021-06-30T23:48:50.700078Z","iopub.status.idle":"2021-06-30T23:48:50.726411Z","shell.execute_reply.started":"2021-06-30T23:48:50.700056Z","shell.execute_reply":"2021-06-30T23:48:50.725688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective,n_trials= 20)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.728122Z","iopub.execute_input":"2021-06-30T23:48:50.728656Z","iopub.status.idle":"2021-06-30T23:48:50.750498Z","shell.execute_reply.started":"2021-06-30T23:48:50.728623Z","shell.execute_reply":"2021-06-30T23:48:50.74923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Catboost","metadata":{}},{"cell_type":"code","source":"#cat_features = np.arange(0,train_features_encoded.shape[1]).tolist()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.751726Z","iopub.execute_input":"2021-06-30T23:48:50.752047Z","iopub.status.idle":"2021-06-30T23:48:50.765311Z","shell.execute_reply.started":"2021-06-30T23:48:50.752014Z","shell.execute_reply":"2021-06-30T23:48:50.76467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n\n\nparams = {\n    'learning_rate': 0.010516504167628355, \n     'depth': 10,\n     'l2_leaf_reg': 15.358647811187538,\n     'random_strength': 2.9499283334899307, \n     'border_count': 254,\n     'grow_policy': 'SymmetricTree', \n     'min_data_in_leaf': 206        \n}\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.766225Z","iopub.execute_input":"2021-06-30T23:48:50.766546Z","iopub.status.idle":"2021-06-30T23:48:50.78548Z","shell.execute_reply.started":"2021-06-30T23:48:50.766513Z","shell.execute_reply":"2021-06-30T23:48:50.78465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nX=train_features_encoded.astype(int)\ny= train_labels_num\n\n\nparams_cb = params\n\nparams_cb [\"loss_function\"] = 'MultiClass'\nparams_cb [\"od_wait\"] = 100\nparams_cb [\"od_type\"] = 'Iter'\n#params_cb [\"max_ctr_complexity\"] = 15\nparams_cb [\"task_type\"] = \"GPU\"\nparams_cb[\"cat_features\"] = cat_features\n\n\n\nname = 'catboost_3seeds_5fold'\nk=5\nseed_list=[0,1,2]\nrandom_seed=0\nkf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\noof = np.zeros((len(X),9))\ntest_preds_list = []\nscore_list = []\nfold=1\n  \nsplits = list(kf.split(X,y))\nfold = 1\nfor train_idx, val_idx in splits:\n  X_train, X_val = X[train_idx], X[val_idx]\n  y_train, y_val = y[train_idx], y[val_idx]\n\n  val_preds_list = []\n\n  for seed in seed_list:\n    \n    # fit and run model\n    params_cb['random_state'] = seed\n        \n    model = CatBoostClassifier(**params_cb,\n            iterations=100000,\n            use_best_model=True,\n)\n\n    model.fit(X_train,y=y_train,\n              embedding_features=None,\n              use_best_model=True,\n               early_stopping_rounds=100,\n              eval_set=[(X_val,y_val)],\n              verbose=500)\n    \n\n    \n    val_preds_list.append(model.predict_proba(X_val))\n    test_preds_list.append(model.predict_proba(test_features_encoded.astype(int)))\n    \n  oof[val_idx] = np.mean(val_preds_list,axis=0)\n  score = log_loss(y_val, oof[val_idx])\n  print(f\"fold: {fold},log_loss: {score}\")\n  score_list.append(score)\n  # print(f\"fold: {fold}, class0 tr %: {y_train.value_counts()[0]/len(y_train)}, class0 val %: {y_val.value_counts()[0]/len(y_val)} \")\n  fold +=1\n  \ncv_logloss = np.mean(score_list)\nprint(f\"{name} ,log_loss: {cv_logloss}\")\n\npreds= np.mean(test_preds_list,axis=0)\n\n\nfile_name_oof = name + \"_oof.txt\"\nfile_name_test = name + \"_test.csv\"\nwith open(file_name_oof, \"wb\") as fp:\n      pickle.dump(oof, fp)\n\n#files.download(file_name_oof)\nsubmission.iloc[:,1:] = pd.DataFrame(preds).values\nsubmission.to_csv(file_name_test,index=None)\n#files.download(file_name_test) \n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.786731Z","iopub.execute_input":"2021-06-30T23:48:50.787114Z","iopub.status.idle":"2021-06-30T23:48:50.801536Z","shell.execute_reply.started":"2021-06-30T23:48:50.787065Z","shell.execute_reply":"2021-06-30T23:48:50.800705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Catboost tuning","metadata":{}},{"cell_type":"code","source":"'''\n# for the fixed learning rate, use the opt n iterations and tune the tree hyperparameters\ndef objective(trial,X=train_features_encoded.astype(int),y= train_labels_num):\n  \"\"\"\n  \"\"\"\n \n\n  param_space = {\n        \"od_type\" : \"Iter\",\n        \"od_wait\" : 100,\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-2, 1e-1),\n         \"depth\": trial.suggest_int(\"depth\", 1, 10),\n        \"l2_leaf_reg\": trial.suggest_loguniform('l2_leaf_reg', 1e-4, 1e3),\n        \"random_strength\": trial.suggest_float(\"random_strength\",0,3),\n        # \"bagging_temperature\": trial.suggest_int(\"bagging_temperature\",0,100),\n        \"border_count\": trial.suggest_int(\"border_count\",254,254),\n        \"grow_policy\":trial.suggest_categorical(\"grow_policy\",[\"Depthwise\",\"SymmetricTree\",\"Lossguide\"]),\n        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 20, 300)\n\n        }\n            \n  #X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=.1,random_state=2021,stratify=y)\n  k=5\n  seed_list=[0]\n  random_seed=0\n  kf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\n  oof = np.zeros((len(X),9))\n  score_list = []\n  fold=1\n  \n  splits = list(kf.split(X,y))\n  for train_idx, val_idx in splits:\n    X_train, X_val = X[train_idx,:], X[val_idx,:]\n    y_train, y_val = y[train_idx], y[val_idx]\n\n    #if fold > 1:break\n\n  \n    val_preds_list = []\n  \n    \n    for seed in seed_list:\n      # fit and run model\n      param_space['random_state'] = seed\n      param_space [\"loss_function\"] = 'MultiClass'\n\n      param_space[\"cat_features\"] = cat_features\n\n      model = CatBoostClassifier(**param_space,\n                                task_type=\"GPU\",\n                                 iterations=100000,\n                                 use_best_model=True)\n      \n      model.fit(X_train,y=y_train,\n              embedding_features=None,\n              use_best_model=True,\n                early_stopping_rounds=100,\n              eval_set=[(X_val,y_val)],\n              verbose=500)\n    \n    \n      val_preds_list.append(model.predict_proba(X_val))\n     #test_preds_list.append(model.predict_proba(X_test)[:,1])\n    \n    oof[val_idx] = np.mean(val_preds_list,axis=0)\n    score = log_loss(y_val, oof[val_idx])\n    print(f\"fold: {fold},logloss: {score}\")\n    score_list.append(score)\n    fold +=1\n  \n  cv_logloss = np.mean(score_list)\n  \n  return cv_logloss\n  '''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.802478Z","iopub.execute_input":"2021-06-30T23:48:50.802777Z","iopub.status.idle":"2021-06-30T23:48:50.824326Z","shell.execute_reply.started":"2021-06-30T23:48:50.802754Z","shell.execute_reply":"2021-06-30T23:48:50.823843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective,n_trials= 20)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.82512Z","iopub.execute_input":"2021-06-30T23:48:50.825394Z","iopub.status.idle":"2021-06-30T23:48:50.846736Z","shell.execute_reply.started":"2021-06-30T23:48:50.825373Z","shell.execute_reply":"2021-06-30T23:48:50.845635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Logistic Regression","metadata":{}},{"cell_type":"code","source":"'''\nencoder = OneHotEncoder()\nall_encoded = encoder.fit_transform(pd.DataFrame(train_features_encoded).append(pd.DataFrame(test_features_encoded)))\n#X = all_encoded[0:len(X)]\n#X_test = all_encoded[len(X):]\ntrain_features_onehot = all_encoded.tocsr()[0:len(train_features_encoded)]\ntest_features_onehot = all_encoded [len(train_features_encoded):]\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.847778Z","iopub.execute_input":"2021-06-30T23:48:50.847997Z","iopub.status.idle":"2021-06-30T23:48:50.863588Z","shell.execute_reply.started":"2021-06-30T23:48:50.847975Z","shell.execute_reply":"2021-06-30T23:48:50.86243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nparams = { \n     'C': 0.0011494694737913215, \n      'multi_class': 'multinomial', \n    'penalty':'elasticnet',\n          'solver': 'saga',\n      'class_weight': None, \n      'l1_ratio': 0.508725921329706,\n    'max_iter':10000,\n          'n_jobs':-1\n}\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.865297Z","iopub.execute_input":"2021-06-30T23:48:50.86575Z","iopub.status.idle":"2021-06-30T23:48:50.880192Z","shell.execute_reply.started":"2021-06-30T23:48:50.865711Z","shell.execute_reply":"2021-06-30T23:48:50.878196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nX=train_features_onehot\ny=train_labels_num\n\n\nname = 'logistic_regression'\nk=5\nseed_list=[0,1,2]\nrandom_seed=0\nkf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\noof = np.zeros((X.shape[0],9))\ntest_preds_list = []\nscore_list = []\nfold=1\n  \nsplits = list(kf.split(X,y))\nfold = 1\nfor train_idx, val_idx in splits:\n  X_train, X_val = X[train_idx], X[val_idx]\n  y_train, y_val = y[train_idx], y[val_idx]\n\n  val_preds_list = []\n\n  for seed in seed_list:\n    \n    # fit and run model\n    \n    base_model = LogisticRegression(**params,random_state=seed)\n    model = CalibratedClassifierCV(base_model, method='sigmoid', cv=k)\n\n\n    model.fit(X_train,y=y_train)\n\n    \n    val_preds_list.append(model.predict_proba(X_val))\n    test_preds_list.append(model.predict_proba(test_features_onehot))\n    \n  oof[val_idx] = np.mean(val_preds_list,axis=0)\n  score = log_loss(y_val, oof[val_idx])\n  print(f\"fold: {fold},log_loss: {score}\")\n  score_list.append(score)\n  # print(f\"fold: {fold}, class0 tr %: {y_train.value_counts()[0]/len(y_train)}, class0 val %: {y_val.value_counts()[0]/len(y_val)} \")\n  fold +=1\n  \ncv_logloss = np.mean(score_list)\nprint(f\"{name} ,log_loss: {cv_logloss}\")\n\npreds= np.mean(test_preds_list,axis=0)\n\n\nfile_name_oof = \"logistic_3seeds_oof.txt\"\nfile_name_test = \"logistic_3seeds_test.csv\"\nwith open(file_name_oof, \"wb\") as fp:\n      pickle.dump(oof, fp)\n\n#files.download(file_name_oof)\n\nsubmission.iloc[:,1:] = pd.DataFrame(preds).values\nsubmission.to_csv(file_name_test,index=None)\n#files.download(file_name_test) \n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.882011Z","iopub.execute_input":"2021-06-30T23:48:50.882496Z","iopub.status.idle":"2021-06-30T23:48:50.894506Z","shell.execute_reply.started":"2021-06-30T23:48:50.882452Z","shell.execute_reply":"2021-06-30T23:48:50.89335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Logistic Regression tuning","metadata":{}},{"cell_type":"code","source":"'''\n# for the fixed learning rate, use the opt n iterations and tune the tree hyperparameters\ndef objective(trial,X=train_features_onehot, y=train_labels_num):\n  \"\"\"\n  \"\"\"\n  param_space = {\n          'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n          'penalty':'elasticnet',\n          'solver': 'saga',\n          'multi_class':trial.suggest_categorical('multi_class',['ovr','multinomial']),\n          'max_iter':10000,\n          'class_weight':trial.suggest_categorical('class_weight',['balanced',None])  ,\n           'n_jobs':-1,\n          'l1_ratio':trial.suggest_uniform('l1_ratio', 0, 1)\n                }\n            \n  #X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=.1,random_state=2021,stratify=y)\n  k=5\n  seed_list=[0]\n  random_seed=0\n  kf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\n  oof = np.zeros((X.shape[0],9))\n  score_list = []\n  fold=1\n  \n  splits = list(kf.split(X,y))\n  for train_idx, val_idx in splits:\n    X_train, X_val = X[train_idx,:], X[val_idx,:]\n    y_train, y_val = y[train_idx], y[val_idx]\n  \n    val_preds_list = []\n  \n    for seed in seed_list:\n      # fit and run model\n      param_space['random_state'] = seed\n\n      model = LogisticRegression(**param_space)\n      #model = CalibratedClassifierCV(base_model, method='sigmoid', cv=k, n_jobs=-1)\n      model.fit(X_train,y=y_train)\n\n    \n      val_preds_list.append(model.predict_proba(X_val))\n     #test_preds_list.append(model.predict_proba(X_test)[:,1])\n    \n    oof[val_idx] = np.mean(val_preds_list,axis=0)\n    score = log_loss(y_val, oof[val_idx])\n    print(f\"fold: {fold},logloss: {score}\")\n    score_list.append(score)\n    fold +=1\n  \n  cv_logloss = np.mean(score_list)\n  \n  return cv_logloss\n  '''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.896729Z","iopub.execute_input":"2021-06-30T23:48:50.897146Z","iopub.status.idle":"2021-06-30T23:48:50.916668Z","shell.execute_reply.started":"2021-06-30T23:48:50.897076Z","shell.execute_reply":"2021-06-30T23:48:50.915349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective,n_trials= 30)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.917898Z","iopub.execute_input":"2021-06-30T23:48:50.918191Z","iopub.status.idle":"2021-06-30T23:48:50.934591Z","shell.execute_reply.started":"2021-06-30T23:48:50.918163Z","shell.execute_reply":"2021-06-30T23:48:50.933678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest","metadata":{}},{"cell_type":"code","source":"'''\n\nparams = {\n    'max_depth': 25, \n 'n_estimators': 1270, \n 'max_features': 'sqrt', \n 'min_samples_split': 10, \n 'bootstrap': False, \n 'min_samples_leaf': 2\n}\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.936792Z","iopub.execute_input":"2021-06-30T23:48:50.937413Z","iopub.status.idle":"2021-06-30T23:48:50.945648Z","shell.execute_reply.started":"2021-06-30T23:48:50.937364Z","shell.execute_reply":"2021-06-30T23:48:50.944913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ntrain_features_encoded = train_features_encoded.astype(np.int16)\ntest_features_encoded = test_features_encoded.astype(np.int16)\ntrain_labels_num = train_labels_num.astype(np.int8)\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.947202Z","iopub.execute_input":"2021-06-30T23:48:50.947603Z","iopub.status.idle":"2021-06-30T23:48:50.968331Z","shell.execute_reply.started":"2021-06-30T23:48:50.94757Z","shell.execute_reply":"2021-06-30T23:48:50.966882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nX=train_features_encoded\ny=train_labels_num\n\nname = 'random_forest'\nk=5\nseed_list=[0,1,2]\nrandom_seed=0\nkf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\noof = np.zeros((len(X),9))\ntest_preds_list = []\nscore_list = []\nfold=1\n  \nsplits = list(kf.split(X,y))\nfor train_idx, val_idx in splits:\n  X_train, X_val = X[train_idx], X[val_idx]\n  y_train, y_val = y[train_idx], y[val_idx]\n\n  val_preds_list = []\n\n  for seed in seed_list:\n    \n    # fit and run model\n    \n    model = RandomForestClassifier(**params,\n                                        random_state=seed,  \n                                        n_jobs=-1,\n                                        criterion = \"entropy\",\n                                       verbose=200)\n    #model = CalibratedClassifierCV(base_model, method='sigmoid', cv=k, n_jobs=-1)\n\n    model.fit(X_train,y=y_train)\n\n    \n    val_preds_list.append(model.predict_proba(X_val))\n    test_preds_list.append(model.predict_proba(test_features_encoded))\n    \n  oof[val_idx] = np.mean(val_preds_list,axis=0)\n\n  del val_preds_list\n    \n  score = log_loss(y_val, oof[val_idx])\n  print(f\"fold: {fold},log_loss: {score}\")\n  score_list.append(score)\n\n  del score\n\n  # print(f\"fold: {fold}, class0 tr %: {y_train.value_counts()[0]/len(y_train)}, class0 val %: {y_val.value_counts()[0]/len(y_val)} \")\n  fold +=1\n  \ncv_logloss = np.mean(score_list)\nprint(f\"{name} ,log_loss: {cv_logloss}\")\n\npreds= np.mean(test_preds_list,axis=0)\n\ndel test_preds_list\n\nfile_name_oof = \"rfc_3seed5f_oof.txt\"\nfile_name_test = \"rfc_3seed5f_test.csv\"\nwith open(file_name_oof, \"wb\") as fp:\n      pickle.dump(oof, fp)\n\ndel oof\n\n#files.download(file_name_oof)\nsubmission = pd.read_csv(\"../input/tabular-playground-series-jun-2021/sample_submission.csv\")\n\nsubmission.iloc[:,1:] = pd.DataFrame(preds)\nsubmission.to_csv(file_name_test,index=None)\n#files.download(file_name_test) \n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.969776Z","iopub.execute_input":"2021-06-30T23:48:50.970061Z","iopub.status.idle":"2021-06-30T23:48:50.987124Z","shell.execute_reply.started":"2021-06-30T23:48:50.970032Z","shell.execute_reply":"2021-06-30T23:48:50.985764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest tuning","metadata":{}},{"cell_type":"code","source":"'''\nrandom_seed=0\n\n# for the fixed learning rate, use the opt n iterations and tune the tree hyperparameters\ndef objective(trial,X=train_features_encoded, y=train_labels_num):\n  \"\"\"\n  \"\"\"\n  param_space = {\n               'max_depth': trial.suggest_int('max_depth', 2, 30),\n               'n_estimators': trial.suggest_int('n_estimators', 200,2000,10),\n               'max_features': trial.suggest_categorical('max_features',['auto','sqrt']),\n               'min_samples_split':trial.suggest_categorical('min_samples_split',[2,5,10]),\n               'bootstrap' : trial.suggest_categorical('bootstrap',[True,False]),\n               'min_samples_leaf':trial.suggest_categorical('min_samples_leaf',[2,5,10]),\n               # 'min_impurity_decrease':trial.suggest_float('min_impurity_decrease', 0,0.005),\n              # 'class_weight' : trial.suggest_categorical('class_weight',['balanced','balanced_subsample',None]),\n              #'max_samples':trial.suggest_float('max_samples', 0.01,0.95),\n              #'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 2,100)\n               \n                }\n            \n  model = RandomForestClassifier(**param_space,\n                                 random_state=random_seed,\n                                 n_jobs=-1, \n                                 criterion = \"entropy\")\n  kf = StratifiedKFold(n_splits=5,shuffle=True,random_state=random_seed)\n  scores = cross_val_score(model,X,y,scoring='neg_log_loss',cv=kf)\n  cv_score = -1*scores.mean()\n      \n  return cv_score\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:50.988476Z","iopub.execute_input":"2021-06-30T23:48:50.98875Z","iopub.status.idle":"2021-06-30T23:48:51.011104Z","shell.execute_reply.started":"2021-06-30T23:48:50.988721Z","shell.execute_reply":"2021-06-30T23:48:51.009315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective,n_trials= 20)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:51.012494Z","iopub.execute_input":"2021-06-30T23:48:51.012784Z","iopub.status.idle":"2021-06-30T23:48:51.029168Z","shell.execute_reply.started":"2021-06-30T23:48:51.012754Z","shell.execute_reply":"2021-06-30T23:48:51.0279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#study.best_params","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:51.030298Z","iopub.execute_input":"2021-06-30T23:48:51.030856Z","iopub.status.idle":"2021-06-30T23:48:51.042359Z","shell.execute_reply.started":"2021-06-30T23:48:51.030826Z","shell.execute_reply":"2021-06-30T23:48:51.040698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stacking\n\nBe careful of leaking in training, so we would select the same KFold seed for every base model and during stacking.","metadata":{}},{"cell_type":"markdown","source":"## Import the base model results","metadata":{}},{"cell_type":"markdown","source":"Cross folds validation sets prediction results fron each base model","metadata":{}},{"cell_type":"code","source":"'''\ninput_val = []\n\nval_result = [\"../input/base-model/Base models results/xgboost_3seed_5fold_oof.txt\",\n               \"../input/base-model/Base models results/lightgbm_3seed_5fold_oof.txt\",\n                \"../input/base-model/Base models results/catboost_3seeds_5fold_oof.txt\",\n              #  \"../input/base-model/Base models results/rfc_3seed5f_oof.txt\",\n               # \"../input/base-model/Base models results/logistic_3seeds_oof.txt\"\n               ]\n\nfor text in val_result:\n    input_val.append(pickle.load(open(text, \"rb\")))\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:51.044327Z","iopub.execute_input":"2021-06-30T23:48:51.044734Z","iopub.status.idle":"2021-06-30T23:48:51.059533Z","shell.execute_reply.started":"2021-06-30T23:48:51.044696Z","shell.execute_reply":"2021-06-30T23:48:51.058901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#input_val = pd.DataFrame(np.hstack(input_val))","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:51.060358Z","iopub.execute_input":"2021-06-30T23:48:51.06057Z","iopub.status.idle":"2021-06-30T23:48:51.082522Z","shell.execute_reply.started":"2021-06-30T23:48:51.060548Z","shell.execute_reply":"2021-06-30T23:48:51.081206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test set prediction results from each base model","metadata":{}},{"cell_type":"code","source":"'''\ninput_test = pd.DataFrame()\n\ntest_result = [\"../input/base-model/Base models results/xgboost_3seed_5fold_test.csv\",\n               \"../input/base-model/Base models results/lightgbm_3seed_5fold_test.csv\",\n                \"../input/base-model/Base models results/catboost_3seeds_5fold_test.csv\",\n               # \"../input/base-model/Base models results/rfc_3seed5f_test.csv\",\n               # \"../input/base-model/Base models results/logistic_3seeds_test.csv\"\n               ]\n\nfor tr in test_result:\n    input_test = pd.concat([input_test, pd.read_csv(tr).iloc[: ,1:]], axis=1, sort=False)\n  '''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:51.083945Z","iopub.execute_input":"2021-06-30T23:48:51.084201Z","iopub.status.idle":"2021-06-30T23:48:51.098963Z","shell.execute_reply.started":"2021-06-30T23:48:51.084178Z","shell.execute_reply":"2021-06-30T23:48:51.098137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#input_test.columns = input_val.columns","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:51.100024Z","iopub.execute_input":"2021-06-30T23:48:51.100359Z","iopub.status.idle":"2021-06-30T23:48:51.113094Z","shell.execute_reply.started":"2021-06-30T23:48:51.10033Z","shell.execute_reply":"2021-06-30T23:48:51.112007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"meta model is ridge classifier with calibrated classifier CV","metadata":{}},{"cell_type":"code","source":"'''\nparams = {\n 'alpha': 62.040049045839396, \n 'solver': 'svd',\n      'max_iter':10000,\n 'class_weight': None}\n '''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:51.114175Z","iopub.execute_input":"2021-06-30T23:48:51.11457Z","iopub.status.idle":"2021-06-30T23:48:51.133721Z","shell.execute_reply.started":"2021-06-30T23:48:51.114496Z","shell.execute_reply":"2021-06-30T23:48:51.132116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nX = input_val\ny = train_labels_num\n\nname = 'stackingridge_5f'\nk=5\nrandom_seed=0\nkf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\noof_stack = np.zeros((len(X),9))\n\n#seed_list=[0,1,2]\nscore_list= []\nfold = 1\ntest_preds_stack = []\n\nfor train_index, test_index in kf.split(X, y):\n    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_val = y[train_index], y[test_index]    \n    \n    rd = CalibratedClassifierCV(RidgeClassifier(**params), n_jobs=-1)\n    \n    rd.fit(X_train, y_train)\n    y_stack = rd.predict_proba(X_val)\n   \n    \n    oof_stack[test_index] = y_stack*1\n    score = log_loss(y_val, oof_stack[test_index])\n    print(f\"fold: {fold},log_loss: {score}\")\n  \n    score_list.append(score)\n    \n    test_preds_stack.append(rd.predict_proba(input_test.values))\n    fold +=1\n\ncv_logloss = np.mean(score_list)\nprint(f\"{name} ,log_loss: {cv_logloss}\")\n\npreds= np.mean(test_preds_stack,axis=0)\n\nfile_name_oof = \"stackingridge_5f_oof.txt\"\nfile_name_test = \"stackingridge_5f_test.csv\"\nwith open(file_name_oof, \"wb\") as fp:\n    pickle.dump(oof_stack, fp)\n\nsubmission = pd.read_csv(\"../input/tabular-playground-series-jun-2021/sample_submission.csv\")\n\nsubmission.iloc[:,1:] = pd.DataFrame(preds)\nsubmission.to_csv(file_name_test,index=None)\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:51.135225Z","iopub.execute_input":"2021-06-30T23:48:51.135956Z","iopub.status.idle":"2021-06-30T23:48:51.152609Z","shell.execute_reply.started":"2021-06-30T23:48:51.135923Z","shell.execute_reply":"2021-06-30T23:48:51.151723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"meta model is lgb","metadata":{}},{"cell_type":"code","source":"'''\nparams = {\n    'boosting_type': 'gbdt',\n    'reg_lambda': 18.47848662046526,\n 'reg_alpha': 0.09586897470473404, \n 'colsample_bytree': 0.4444514204868687,\n 'subsample': 0.373940404514446,\n 'learning_rate': 0.01, \n 'num_leaves': 38, \n 'min_child_samples': 7, \n 'max_depth': 21,\n    'n_estimators':100000,\n               'objective':'multiclass',\n               'metric':'multi_logloss',\n                'n_jobs':-1\n}\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:51.153641Z","iopub.execute_input":"2021-06-30T23:48:51.154005Z","iopub.status.idle":"2021-06-30T23:48:51.1728Z","shell.execute_reply.started":"2021-06-30T23:48:51.15397Z","shell.execute_reply":"2021-06-30T23:48:51.171179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nX = input_val\ny = train_labels_num\n\nname = 'stackinglgb_3seed_5f'\nk=5\nrandom_seed=0\nkf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\noof_stack = np.zeros((X.shape[0],9))\n\nseed_list=[0,1,2]\nscore_list= []\nfold = 1\ntest_preds_stack = []\n\nsplits = list(kf.split(X,y))\n  \nfor train_index, test_index in splits:\n    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_val = y[train_index], y[test_index]    \n    \n    val_preds_list = []\n    \n    for seed in seed_list:\n    \n        params['random_state'] = seed\n\n        model = LGBMClassifier(**params)\n        model.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_val,y_val)],\n                early_stopping_rounds=100,\n                eval_names=['train','val'],verbose=0)\n\n        val_preds_list.append(model.predict_proba(X_val))\n        test_preds_stack.append(model.predict_proba(input_test.values))\n    \n    \n    oof_stack[test_index] = np.mean(val_preds_list,axis=0)\n    score = log_loss(y_val, oof_stack[test_index])\n    print(f\"fold: {fold},log_loss: {score}\")\n  \n    score_list.append(score)\n    fold +=1\n\ncv_logloss = np.mean(score_list)\nprint(f\"{name} ,log_loss: {cv_logloss}\")\n\npreds= np.mean(test_preds_stack,axis=0)\n\nfile_name_oof = name + \"_oof.txt\"\nfile_name_test = name + \"_test.csv\"\nwith open(file_name_oof, \"wb\") as fp:\n    pickle.dump(oof_stack, fp)\n\nsubmission = pd.read_csv(\"../input/tabular-playground-series-jun-2021/sample_submission.csv\")\n\nsubmission.iloc[:,1:] = pd.DataFrame(preds)\nsubmission.to_csv(file_name_test,index=None)\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:51.174693Z","iopub.execute_input":"2021-06-30T23:48:51.17516Z","iopub.status.idle":"2021-06-30T23:48:51.189822Z","shell.execute_reply.started":"2021-06-30T23:48:51.17513Z","shell.execute_reply":"2021-06-30T23:48:51.188218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"meta model is lgb with base models no logistic","metadata":{}},{"cell_type":"code","source":"'''\nparams = {\n    \n    'boosting_type': 'gbdt',\n    'n_estimators':100000,\n               'objective':'multiclass',\n               'metric':'multi_logloss',\n                'n_jobs':-1,\n'reg_lambda': 1.1677970419963015, \n 'reg_alpha': 25.64393399350136,\n 'colsample_bytree': 0.7698192407526574,\n 'subsample': 0.4912058042676565, \n 'learning_rate': 0.01, \n 'num_leaves': 120, \n 'min_child_samples': 365, \n 'max_depth': 4\n}\n'''\n\n'''\nparams = {\n    'boosting_type': 'gbdt',\n    'n_estimators':100000,\n               'objective':'multiclass',\n               'metric':'multi_logloss',\n                'n_jobs':-1,\n'reg_lambda': 0.8189181015375904, \n 'reg_alpha': 0.25487382221563054, \n 'colsample_bytree': 0.1275201917021311, \n 'subsample': 0.6396666339670933, \n 'learning_rate': 0.01, \n 'num_leaves': 44,\n 'min_child_samples': 11, \n 'max_depth': 56\n}\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:51.19254Z","iopub.execute_input":"2021-06-30T23:48:51.192817Z","iopub.status.idle":"2021-06-30T23:48:51.210299Z","shell.execute_reply.started":"2021-06-30T23:48:51.192791Z","shell.execute_reply":"2021-06-30T23:48:51.209199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nX = input_val\ny = train_labels_num\n\nname = 'stackinglgbnolog_3seed_5f'\nk=5\nrandom_seed=0\nkf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\noof_stack = np.zeros((X.shape[0],9))\n\nseed_list=[0,1,2]\nscore_list= []\nfold = 1\ntest_preds_stack = []\n\nsplits = list(kf.split(X,y))\n  \nfor train_index, test_index in splits:\n    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_val = y[train_index], y[test_index]    \n    \n    val_preds_list = []\n    \n    for seed in seed_list:\n    \n        params['random_state'] = seed\n\n        model = LGBMClassifier(**params)\n        model.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_val,y_val)],\n                early_stopping_rounds=100,\n                eval_names=['train','val'],verbose=0)\n\n        val_preds_list.append(model.predict_proba(X_val))\n        test_preds_stack.append(model.predict_proba(input_test.values))\n    \n    \n    oof_stack[test_index] = np.mean(val_preds_list,axis=0)\n    score = log_loss(y_val, oof_stack[test_index])\n    print(f\"fold: {fold},log_loss: {score}\")\n  \n    score_list.append(score)\n    fold +=1\n\ncv_logloss = np.mean(score_list)\nprint(f\"{name} ,log_loss: {cv_logloss}\")\n\npreds= np.mean(test_preds_stack,axis=0)\n\nfile_name_oof = name + \"_oof.txt\"\nfile_name_test = name + \"_test.csv\"\nwith open(file_name_oof, \"wb\") as fp:\n    pickle.dump(oof_stack, fp)\n\nsubmission = pd.read_csv(\"../input/tabular-playground-series-jun-2021/sample_submission.csv\")\n\nsubmission.iloc[:,1:] = pd.DataFrame(preds).values\nsubmission.to_csv(file_name_test,index=None)\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:51.211592Z","iopub.execute_input":"2021-06-30T23:48:51.212022Z","iopub.status.idle":"2021-06-30T23:48:51.232247Z","shell.execute_reply.started":"2021-06-30T23:48:51.211964Z","shell.execute_reply":"2021-06-30T23:48:51.231216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"meta model is xgb with base models no logistic","metadata":{}},{"cell_type":"code","source":"'''\nparams = {\n'lambda': 0.0010446502460788832, \n 'alpha': 1.0638896344949464, \n 'colsample_bytree': 0.899300048854003,\n 'colsample_bynode': 0.457360032783254, \n 'colsample_bylevel': 0.7961501791591739, \n 'subsample': 0.5572526278185042, \n 'eta': 0.01, \n 'grow_policy': 'depthwise', \n 'max_depth': 2, \n 'min_child_weight': 46, \n 'max_bin': 409, \n 'deterministic_histogram': False\n}\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:51.23341Z","iopub.execute_input":"2021-06-30T23:48:51.233817Z","iopub.status.idle":"2021-06-30T23:48:51.255593Z","shell.execute_reply.started":"2021-06-30T23:48:51.233777Z","shell.execute_reply":"2021-06-30T23:48:51.254424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"meta model is xgb with base models logistic","metadata":{}},{"cell_type":"code","source":"'''\nparams = {\n    'lambda': 0.011483926762852138, \n 'alpha': 0.3063338385041086, \n 'colsample_bytree': 0.8674369490772537, \n 'colsample_bynode': 0.7529165609782398, \n 'colsample_bylevel': 0.6927394353409445, \n 'subsample': 0.5541902902608168, \n 'eta': 0.01,\n 'grow_policy': 'lossguide',\n 'max_depth': 4,\n 'min_child_weight': 149, \n 'max_bin': 512, \n 'deterministic_histogram': False\n}\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:51.256706Z","iopub.execute_input":"2021-06-30T23:48:51.257061Z","iopub.status.idle":"2021-06-30T23:48:51.270915Z","shell.execute_reply.started":"2021-06-30T23:48:51.257033Z","shell.execute_reply":"2021-06-30T23:48:51.270314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"meta model is xgb with base models no logistic no rf","metadata":{}},{"cell_type":"code","source":"'''\nparams = {\n    'lambda': 8.78438796741932, \n     'alpha': 1.5156056424257214, \n     'colsample_bytree': 0.6746676803716631, \n     'colsample_bynode': 0.23151927366501895,\n     'colsample_bylevel': 0.6770030260262497, \n     'subsample': 0.4258029694908929,\n     'eta': 0.01,\n     'grow_policy': 'lossguide', \n     'max_depth': 4, \n     'min_child_weight': 37,\n     'max_bin': 288, \n     'deterministic_histogram': False \n}\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:51.272432Z","iopub.execute_input":"2021-06-30T23:48:51.272755Z","iopub.status.idle":"2021-06-30T23:48:51.294872Z","shell.execute_reply.started":"2021-06-30T23:48:51.272727Z","shell.execute_reply":"2021-06-30T23:48:51.293722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nX = input_val\ny = train_labels_num\n\nparams_xgb = params\nparams_xgb[\"tree_method\"] = \"hist\"\nparams_xgb[\"predictor\"] = 'cpu_predictor'\nparams_xgb[\"objective\"] = 'multi:softprob'\nparams_xgb[\"num_class\"] = 9\nparams_xgb[\"eval_metric\"] ='mlogloss'\n\nname = 'stackingxgbnolog_3seed_5f'\nk=5\nrandom_seed=0\nkf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\noof_stack = np.zeros((X.shape[0],9))\n\nseed_list=[0,1,2]\nscore_list= []\nfold = 1\ntest_preds_stack = []\n\nsplits = list(kf.split(X,y))\n  \nfor train_index, test_index in splits:\n    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_val = y[train_index], y[test_index]    \n    \n    val_preds_list = []\n    \n    for seed in seed_list:\n    \n        params['random_state'] = seed\n        \n        dtrain = xgboost.DMatrix(data=X_train, label=y_train)\n        dval = xgboost.DMatrix(data=X_val, label=y_val)\n        dtest = xgboost.DMatrix(data=input_test)\n\n        model = xgboost.train(params_xgb, dtrain,\\\n                       evals=[(dtrain,'train'),(dval,'val')],\\\n                       verbose_eval=False,\n                       early_stopping_rounds=100,\n                       num_boost_round=100000)\n\n        val_preds_list.append(model.predict(dval))\n        test_preds_stack.append(model.predict(dtest))\n    \n    \n    oof_stack[test_index] = np.mean(val_preds_list,axis=0)\n    score = log_loss(y_val, oof_stack[test_index])\n    print(f\"fold: {fold},log_loss: {score}\")\n  \n    score_list.append(score)\n    fold +=1\n\ncv_logloss = np.mean(score_list)\nprint(f\"{name} ,log_loss: {cv_logloss}\")\n\npreds= np.mean(test_preds_stack,axis=0)\n\nfile_name_oof = name + \"_oof.txt\"\nfile_name_test = name + \"_test.csv\"\nwith open(file_name_oof, \"wb\") as fp:\n    pickle.dump(oof_stack, fp)\n\nsubmission = pd.read_csv(\"../input/tabular-playground-series-jun-2021/sample_submission.csv\")\n\nsubmission.iloc[:,1:] = pd.DataFrame(preds).values\nsubmission.to_csv(file_name_test,index=None)\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:51.296649Z","iopub.execute_input":"2021-06-30T23:48:51.297038Z","iopub.status.idle":"2021-06-30T23:48:51.30742Z","shell.execute_reply.started":"2021-06-30T23:48:51.297008Z","shell.execute_reply":"2021-06-30T23:48:51.306711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stacking tuning","metadata":{}},{"cell_type":"markdown","source":"meta model is ridge classifier with calibrated classifier CV","metadata":{}},{"cell_type":"code","source":"'''\n# for the fixed learning rate, use the opt n iterations and tune the tree hyperparameters\ndef objective(trial,X=input_val, y=train_labels_num):\n  \"\"\"\n  \"\"\"\n  param_space = {\n          'alpha': trial.suggest_loguniform('alpha', 1e-3, 1e2),\n          'solver': trial.suggest_categorical('solver',['svd', 'cholesky','sparse_cg', 'lsqr', 'sag', 'saga']),\n          'max_iter':10000,\n          'class_weight':trial.suggest_categorical('class_weight',['balanced',None])  \n           #'n_jobs':-1\n                }\n            \n  #X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=.1,random_state=2021,stratify=y)\n  k=5\n  random_seed=0\n  kf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\n  oof = np.zeros((X.shape[0],9))\n  score_list = []\n  fold=1\n  \n  splits = list(kf.split(X,y))\n    \n  for train_index, test_index in kf.split(X, y):\n    \n    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_val = y[train_index], y[test_index]\n  \n    val_preds_list = []\n  \n    rd = CalibratedClassifierCV(RidgeClassifier(**param_space, random_state=random_seed), n_jobs=-1)\n    \n    rd.fit(X_train, y_train)\n    y_stack = rd.predict_proba(X_val)\n    \n    oof[test_index] = y_stack*1\n    score = log_loss(y_val, oof[test_index])\n    print(f\"fold: {fold},logloss: {score}\")\n    score_list.append(score)\n    fold +=1\n  \n  cv_logloss = np.mean(score_list)\n  \n  return cv_logloss\n  '''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:51.308337Z","iopub.execute_input":"2021-06-30T23:48:51.308651Z","iopub.status.idle":"2021-06-30T23:48:51.32797Z","shell.execute_reply.started":"2021-06-30T23:48:51.308622Z","shell.execute_reply":"2021-06-30T23:48:51.327469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"meta model is lgb","metadata":{}},{"cell_type":"code","source":"'''\n# for the fixed learning rate, use the opt n iterations and tune the tree hyperparameters\ndef objective(trial,X=input_val, y=train_labels_num):\n  \"\"\"\n  \"\"\"\n  param_space = {\n               'device':'gpu',  # Use GPU acceleration\n               'boosting_type': 'gbdt',\n               'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 1e3),\n               'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 1e3),\n               'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1 , 1.0),\n               'subsample': trial.suggest_float('subsample', 0.1, 1.0),\n               'learning_rate': trial.suggest_loguniform('learning_rate', 1e-2, 1e-2),\n               'num_leaves': trial.suggest_int(\"num_leaves\", 31,256),\n               'min_child_samples': trial.suggest_int('min_child_samples', 1, 500),\n               'max_depth':trial.suggest_int('max_depth',3,127),\n               'n_estimators':100000,\n               'objective':'multiclass',\n               'metric':'multi_logloss',\n               # 'n_jobs':-1\n                }\n            \n  #X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=.1,random_state=2021,stratify=y)\n  k=5\n  random_seed=0\n  kf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\n  oof = np.zeros((X.shape[0],9))\n  score_list = []\n  fold=1\n  \n  splits = list(kf.split(X,y))\n    \n  for train_index, test_index in splits:\n    \n    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_val = y[train_index], y[test_index]\n  \n    val_preds_list = []\n  \n    param_space['random_state'] = random_seed\n\n    model = LGBMClassifier(**param_space)\n    model.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_val,y_val)],\n                early_stopping_rounds=100,\n                eval_names=['train','val'],verbose=0)\n\n    y_stack = model.predict_proba(X_val)\n    \n    oof[test_index] = y_stack*1\n    score = log_loss(y_val, oof[test_index])\n    print(f\"fold: {fold},logloss: {score}\")\n    score_list.append(score)\n    fold +=1\n  \n  cv_logloss = np.mean(score_list)\n  \n  return cv_logloss\n  '''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:51.328821Z","iopub.execute_input":"2021-06-30T23:48:51.329144Z","iopub.status.idle":"2021-06-30T23:48:51.35155Z","shell.execute_reply.started":"2021-06-30T23:48:51.329115Z","shell.execute_reply":"2021-06-30T23:48:51.350448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"meta model is lgb with base models no logistic","metadata":{}},{"cell_type":"code","source":"'''\n# for the fixed learning rate, use the opt n iterations and tune the tree hyperparameters\ndef objective(trial,X=input_val, y=train_labels_num):\n  \"\"\"\n  \"\"\"\n  param_space = {\n               #'device':'gpu',  # Use GPU acceleration\n               'boosting_type': 'gbdt',\n               'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 1e3),\n               'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 1e3),\n               'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1 , 1.0),\n               'subsample': trial.suggest_float('subsample', 0.1, 1.0),\n               'learning_rate': trial.suggest_loguniform('learning_rate', 1e-2, 1e-2),\n               'num_leaves': trial.suggest_int(\"num_leaves\", 31,256),\n               'min_child_samples': trial.suggest_int('min_child_samples', 1, 500),\n               'max_depth':trial.suggest_int('max_depth',3,127),\n               'n_estimators':100000,\n               'objective':'multiclass',\n               'metric':'multi_logloss',\n               'n_jobs':-1\n                }\n            \n  #X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=.1,random_state=2021,stratify=y)\n  k=5\n  random_seed=0\n  kf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\n  oof = np.zeros((X.shape[0],9))\n  score_list = []\n  fold=1\n  \n  splits = list(kf.split(X,y))\n    \n  for train_index, test_index in splits:\n    \n    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_val = y[train_index], y[test_index]\n  \n    val_preds_list = []\n  \n    param_space['random_state'] = random_seed\n\n    model = LGBMClassifier(**param_space)\n    model.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_val,y_val)],\n                early_stopping_rounds=100,\n                eval_names=['train','val'],verbose=0)\n\n    y_stack = model.predict_proba(X_val)\n    \n    oof[test_index] = y_stack*1\n    score = log_loss(y_val, oof[test_index])\n    print(f\"fold: {fold},logloss: {score}\")\n    score_list.append(score)\n    fold +=1\n  \n  cv_logloss = np.mean(score_list)\n  \n  return cv_logloss\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:51.352597Z","iopub.execute_input":"2021-06-30T23:48:51.352813Z","iopub.status.idle":"2021-06-30T23:48:51.371925Z","shell.execute_reply.started":"2021-06-30T23:48:51.352791Z","shell.execute_reply":"2021-06-30T23:48:51.37084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective,n_trials= 20)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:51.376026Z","iopub.execute_input":"2021-06-30T23:48:51.376409Z","iopub.status.idle":"2021-06-30T23:48:51.390076Z","shell.execute_reply.started":"2021-06-30T23:48:51.376385Z","shell.execute_reply":"2021-06-30T23:48:51.389004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"meta model is xgb with base models no logistic","metadata":{}},{"cell_type":"code","source":"'''\n# for the fixed learning rate, use the opt n iterations and tune the tree hyperparameters\ndef objective(trial,X=input_val, y=train_labels_num):\n  \"\"\"\n  \"\"\"\n  param_space = {\n              'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n                'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 0.9),\n                'colsample_bynode': trial.suggest_float('colsample_bynode', 0.1, 0.9),\n                'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.1, 0.9),\n                'subsample': trial.suggest_float('subsample', 0.1, 0.9),\n                'eta':trial.suggest_float('eta', 1e-2, 1e-2),\n                'grow_policy': trial.suggest_categorical(\"grow_policy\", ['depthwise','lossguide']),\n                'max_depth': trial.suggest_int('max_depth',2,25),\n                'seed': 0,\n                'min_child_weight': trial.suggest_int('min_child_weight', 0, 300),\n                'max_bin': trial.suggest_int('max_bin', 256, 512),\n                'deterministic_histogram':trial.suggest_categorical('deterministic_histogram',[False]),\n               \"tree_method\" : \"hist\",\n                \"predictor\" : 'cpu_predictor',\n                \"objective\" : 'multi:softprob',\n                 \"num_class\":9\n                  \n                }\n            \n  #X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=.1,random_state=2021,stratify=y)\n  k=5\n  random_seed=0\n  kf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\n  oof = np.zeros((X.shape[0],9))\n  score_list = []\n  fold=1\n  \n  splits = list(kf.split(X,y))\n    \n  for train_index, test_index in splits:\n    \n    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_val = y[train_index], y[test_index]\n  \n    val_preds_list = []\n  \n    param_space['random_state'] = random_seed\n    param_space['n_jobs'] = -1\n\n    dtrain = xgboost.DMatrix(data=X_train, label=y_train)\n    dval = xgboost.DMatrix(data=X_val, label=y_val)\n    #dtest = xgboost.DMatrix(data=test_features_encoded)\n    xgboost.set_config(verbosity=0)\n\n      \n    model = xgboost.train(param_space, dtrain,\\\n                       evals=[(dtrain,'train'),(dval,'val')],\\\n                       verbose_eval=False,\n                       early_stopping_rounds=100,\n                       num_boost_round=100000\n                         )\n\n\n    y_stack = model.predict(dval)\n    \n    oof[test_index] = y_stack*1\n    score = log_loss(y_val, oof[test_index])\n    print(f\"fold: {fold},logloss: {score}\")\n    score_list.append(score)\n    fold +=1\n  \n  cv_logloss = np.mean(score_list)\n  \n  return cv_logloss\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:51.392183Z","iopub.execute_input":"2021-06-30T23:48:51.392651Z","iopub.status.idle":"2021-06-30T23:48:51.414934Z","shell.execute_reply.started":"2021-06-30T23:48:51.392542Z","shell.execute_reply":"2021-06-30T23:48:51.413673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective,n_trials= 20)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:51.417921Z","iopub.execute_input":"2021-06-30T23:48:51.418329Z","iopub.status.idle":"2021-06-30T23:48:51.437906Z","shell.execute_reply.started":"2021-06-30T23:48:51.4183Z","shell.execute_reply":"2021-06-30T23:48:51.436695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Clipping Ends","metadata":{}},{"cell_type":"markdown","source":"Just for experiments. No improvement is observed.","metadata":{}},{"cell_type":"code","source":"\noof_stacking=pickle.load(open(\"../input/stacking-30062021/stackingxgbnolognorf_3seed_5f_oof.txt\", \"rb\"))\ntest_stacking=pd.read_csv(\"../input/stacking-30062021/stackingxgbnolognorf_3seed_5f_test.csv\").iloc[: ,1:]\n","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:48:51.441139Z","iopub.execute_input":"2021-06-30T23:48:51.441546Z","iopub.status.idle":"2021-06-30T23:48:52.108964Z","shell.execute_reply.started":"2021-06-30T23:48:51.441472Z","shell.execute_reply":"2021-06-30T23:48:52.108257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nX = oof_stacking\ny = train_labels_num\n\nbest_clip = 0\nclipd={0:0,\n      0.005:0,\n      0.01:0,\n      0.015:0,\n      0.02:0}\n\nk=5\nrandom_seed=0\nkf = StratifiedKFold(n_splits=k,shuffle=True,random_state=random_seed)\nsplits = list(kf.split(X,y))\n\nfor cli in clipd.keys():\n\n    fold=1\n    oof_stack = np.zeros((X.shape[0],9))\n    score_list= []\n    \n    for train_index, test_index in splits:\n        X_train, X_val = X[train_index], X[test_index]\n        y_train, y_val = y[train_index], y[test_index]    \n\n        oof_stack[test_index] = np.clip(X_val, cli, 1-cli)\n        score = log_loss(y_val, oof_stack[test_index])\n        #print(f\"fold: {fold},log_loss: {score}\")\n\n        score_list.append(score)\n        fold +=1\n\n    cv_logloss = np.mean(score_list)\n    clipd[cli]=cv_logloss\n    print(f\"{cli} clip,log_loss: {cv_logloss}\")\n\nbest_clip=min(clipd, key=clipd.get)\npreds= np.clip(test_stacking, best_clip, 1-best_clip)\noof_stack= np.clip(oof_stacking, best_clip, 1-best_clip)\nprint(f\"Best clip is {best_clip}\")\n\nfile_name_oof = str(best_clip) + \"clip_oof.txt\"\nfile_name_test = str(best_clip) + \"clip_test.csv\"\nwith open(file_name_oof, \"wb\") as fp:\n    pickle.dump(oof_stack, fp)\n\nsubmission = pd.read_csv(\"../input/tabular-playground-series-jun-2021/sample_submission.csv\")\n\nsubmission.iloc[:,1:] = pd.DataFrame(preds)\nsubmission.to_csv(file_name_test,index=None)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-30T23:49:21.360558Z","iopub.execute_input":"2021-06-30T23:49:21.360807Z","iopub.status.idle":"2021-06-30T23:49:24.589016Z","shell.execute_reply.started":"2021-06-30T23:49:21.360783Z","shell.execute_reply":"2021-06-30T23:49:24.588067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Performance Log","metadata":{}},{"cell_type":"markdown","source":"Performance\n\nLGB\nlightgbm_3seed_5fold ,log_loss: 1.744902147971151\npublic 1.74898 # change save data for stacking, version 81\n\nXGB\nxgboost_3seed_5fold ,log_loss: 1.7435762563824553\npublic 1.74756\n\nRandom Forest\nrandom_forest ,log_loss: 1.7544150313584528\npublic 1.75642 # change save data for stacking, version 79\n\nCatboost\ncatboost_3seeds_5fold ,log_loss: 1.7446580996538827\npublic 1.74870 # change save data for stacking, version 72\n\nLogistic Regression\nlogistic_regression ,log_loss: 1.7676670908351035\npublic 1.77073\n\nStacking ridge\nstackingridge_5f ,log_loss: 1.750612802054284\npublic 1.75346\n\nStacking lgb\nstackinglgb_3seed_5f ,log_loss: 1.7427530499190707\npublic 1.74649\n\nStacking lgb no logistic\nstackinglgbnolog_3seed_5f ,log_loss: 1.742280337930729\npublic 1.74618 # version 65\n\nsame # repeat with better base model but worse stacking, version 85\nstackinglgbnolog_3seed_5f ,log_loss: 1.7425574363337255\npublic 1.74643\n\nStacking xgb no logistic\nstackingxgbnolog_3seed_5f ,log_loss: 1.7416487316326503\npublic 1.74587 # version 90\n\nStacking xgb with logistic\nstackingxgblog_3seed_5f ,log_loss: 1.741866647633571\npublic 1.74573 # version 93\n\nStacking xgb no logistic no rf\nstackingxgbnolognorf_3seed_5f ,log_loss: 1.741812529353016\npublic 1.74603 # version 96","metadata":{}}]}